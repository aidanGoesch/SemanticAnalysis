from openai import OpenAI
from tqdm import tqdm
import numpy as np
import pandas as pd
from google import genai
import anthropic as a
import os
import time
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv(Path(__file__).parent.parent.parent / ".env")

OPENAI_API_KEY = os.getenv("OPEN_AI_API_KEY")
HUGGING_FACE_API_KEY = os.getenv("HUGGING_FACE_API_KEY")
CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")



story_prompts = [
    "Old friend calls after twenty years of silence.",
    "You find someone’s wallet and recognize the photo inside.",
    "Neighbor asks you to keep a strange secret.",
    "You overhear a conversation not meant for you.",
    "Unexpected letter arrives with no return address or name.",
    "A chance meeting changes your entire daily routine.",
    "You help a stranger and they never say thanks.",
    "Lost phone reveals someone’s hidden double life.",
    "You see someone you know pretending not to notice.",
    "Childhood home is up for sale again."
]


def openai(temp: float, story:str, model_id:str="gpt-5.2-2025-12-11"):
    """
    Function that returns a short story generated by an OpenAI LLM
    """
    client = OpenAI(api_key=OPENAI_API_KEY)
    response = client.chat.completions.create(
        model=model_id,
        messages=[
            {"role": "user", "content": f"Write a short story between 7-13 sentences long about the following topic: {story}. Do not include any metacommentary, only return the story."}
        ],
        temperature=temp
    )
    return response.choices[0].message.content

def google(temp: float, story:str, model_id:str="gemini-3-flash-preview"):
    """
    Function that returns a short story generated by a Google LLM
    """
    client = genai.Client(api_key=GOOGLE_API_KEY)
    
    for attempt in range(5):
        try:
            response = client.models.generate_content(
                model=model_id, 
                contents=f"Write a short story between 7-13 sentences long about the following topic: {story}. Do not include any metacommentary, only return the story.",
                config={"temperature": temp}
            )
            return response.candidates[0].content.parts[0].text
        except Exception as e:
            if attempt == 4:
                raise e
            time.sleep(2 ** attempt)

def anthropic(temp: float, story:str, model_id:str="claude-sonnet-4-5-20250929"):
    """
    Function that returns a short story generated by an Anthropic LLM
    """
    client = a.Anthropic(api_key=CLAUDE_API_KEY)
    
    response = client.messages.create(
        model=model_id,
        max_tokens=1000,
        temperature=temp,
        messages=[
            {
                "role": "user",
                "content": f"Write a short story between 7-13 sentences long about the following topic: {story}. Do not include any metacommentary, only return the story."
            }
        ]
    )
    
    return response.content[0].text


def main(provider:str):
    temps = np.linspace(0.05, 1, 20)
    data = pd.DataFrame(columns=["temperature", "topic", "story"])
    
    provider_funcs = {"openai": openai, "google": google, "anthropic": anthropic}
    generate_func = provider_funcs[provider]

    for temp in tqdm(temps):
        for story in tqdm(story_prompts, leave=False):
            generated_story = generate_func(temp, story)
            data = pd.concat([data, pd.DataFrame({"temperature": [temp], "topic": [story], "story": [generated_story]})], ignore_index=True)
        
    data.to_csv(f"./syntehtic-stories-{provider}.csv")
            

if __name__ == "__main__":    
    # main(provider="openai")
    # print("OpenAI Done")
    main(provider="google")
    print("Google Done")
    # main(provider="anthropic")
    # print("Anthropic Done")
